{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": "<a href=\"https://colab.research.google.com/github/mforoozandeh/ctrl-freeq/blob/main/src/examples/api_gpu_cpu_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
   "id": "1175b158ed5a97a8"
  },
  {
   "metadata": {
    "id": "70740e1a1bba7a96"
   },
   "cell_type": "markdown",
   "source": [
    "# ctrl-freeq: CPU vs CUDA demo - Google Colab\n",
    "# This notebook demonstrates selecting compute_resource (cpu/gpu) in the API and comparing runtimes.\n"
   ],
   "id": "70740e1a1bba7a96"
  },
  {
   "metadata": {
    "id": "e6e391ee480befcd"
   },
   "cell_type": "markdown",
   "source": "Clone the repo and install\n```bash\n!git clone https://github.com/mforoozandeh/ctrl-freeq.git\n%cd /content/ctrl-freeq\n!pip install -e .\n```",
   "id": "e6e391ee480befcd"
  },
  {
   "cell_type": "code",
   "source": "!git clone https://github.com/mforoozandeh/ctrl-freeq.git",
   "metadata": {
    "id": "4AyiEqjqzQDk"
   },
   "id": "4AyiEqjqzQDk",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "%cd /content/ctrl-freeq",
   "metadata": {
    "id": "3wXvJkm0c5u_"
   },
   "id": "3wXvJkm0c5u_",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8d0ebe25"
   },
   "source": "!pip install -e .",
   "id": "8d0ebe25",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b61f53d1",
    "ExecuteTime": {
     "end_time": "2026-02-18T23:14:08.156278Z",
     "start_time": "2026-02-18T23:14:06.714607Z"
    }
   },
   "source": "import time\nimport torch\nfrom ctrl_freeq.api import CtrlFreeQAPI, load_single_qubit_config\n\nprint(\"CUDA available:\", torch.cuda.is_available())\ncompute_resource = \"gpu\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Requested compute_resource =\", compute_resource)\n\n# Load example config via API, then extract a mutable dict\nbase_api = load_single_qubit_config()\nconfig = dict(base_api.config)\nconfig[\"compute_resource\"] = compute_resource\n# Optional override of CPU threads\n# config['cpu_cores'] = 2\n\n# Rebuild the API with the modified configuration\napi = CtrlFreeQAPI(config)\n\nstart = time.time()\n_ = api.run_optimization()\nelapsed = time.time() - start\nprint(\"Elapsed (s):\", round(elapsed, 3))",
   "id": "b61f53d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1b0219a9540df999",
   "metadata": {
    "id": "1b0219a9540df999"
   },
   "source": [
    "# Optional: compare CPU vs GPU on CUDA-enabled runtimes\n",
    "from copy import deepcopy\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cfg_cpu = deepcopy(config)\n",
    "    cfg_cpu[\"compute_resource\"] = \"cpu\"\n",
    "    api_cpu = CtrlFreeQAPI(cfg_cpu)\n",
    "    t0 = time.time()\n",
    "    api_cpu.run_optimization()\n",
    "    t1 = time.time()\n",
    "    cpu_time = round(t1 - t0, 3)\n",
    "\n",
    "    cfg_gpu = deepcopy(config)\n",
    "    cfg_gpu[\"compute_resource\"] = \"gpu\"\n",
    "    api_gpu = CtrlFreeQAPI(cfg_gpu)\n",
    "    t0 = time.time()\n",
    "    api_gpu.run_optimization()\n",
    "    t1 = time.time()\n",
    "    gpu_time = round(t1 - t0, 3)\n",
    "\n",
    "    print(\"CPU elapsed (s):\", cpu_time)\n",
    "    print(\"CUDA elapsed (s):\", gpu_time)\n",
    "else:\n",
    "    print(\"CUDA not available on this runtime; CPU-only demo ran above.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a83dc3d8b5ebde2c",
   "metadata": {
    "id": "a83dc3d8b5ebde2c"
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "A100",
   "include_colab_link": true
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}